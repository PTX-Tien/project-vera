# ğŸ§¬ Project Vera: AI Research Agent

![Build Status](https://github.com/PTX-Tien/project-vera/actions/workflows/ci_pipeline.yml/badge.svg)
![Python](https://img.shields.io/badge/Python-3.10-blue)
![Frontend](https://img.shields.io/badge/Next.js-14-black)
![Backend](https://img.shields.io/badge/FastAPI-0.109-009485)
![AI](https://img.shields.io/badge/LangGraph-Stateful-orange)

**Project Vera** is a production-grade, Full-Stack AI Research Agent capable of document analysis, web synthesis, and context-aware reasoning.

It features a **Hybrid Architecture** that combines Neural AI (Llama 3) with Symbolic Logic (LangGraph) to dynamically switch between **RAG (Document Search)**, **Web Research**, and **Instant Chitchat** modes for optimal performance and cost efficiency.

---

## ğŸ—ï¸ Architecture

The system follows a **Client-Server architecture** separating the React-based frontend from the Async Python backend.

```mermaid
graph TD
    User(["ğŸ‘¤ User"]) -->|Chat & Uploads| UI["ğŸ’» Next.js Frontend (Port 3000)"]
    UI -->|JSON / Streams| API["ğŸš€ FastAPI Backend (Port 8000)"]
    
    subgraph "Backend Core"
        API -->|Route| Graph{"LangGraph Orchestrator"}
        
        Graph -->|General Chat| Chitchat["âš¡ Instant Reply (No Cost)"]
        Graph -->|Document Query| RAG["ğŸ“„ FAISS + PDF Search"]
        Graph -->|Complex Query| Agent["ğŸ§  Llama 3 8B (NVIDIA NIM)"]
        
        Agent -->|Web Search| Tools["ğŸ” Tavily Search API"]
    end
    
    subgraph "State Management"
        Graph <-->|Read / Write| Memory[("ğŸ“ Session Memory")]
    end
```

---

## ğŸš€ Key Features

### ğŸ§  Logic & Reasoning
- Powered by **Meta Llama 3 (8B)** via optimized **NVIDIA NIM** endpoints.

- **Intelligent Routing**: Dynamically switches between retrieval, search, and conversation modes.

- LangGraph-driven control flow ensures **deterministic** and **debuggable** agent behavior.

### ğŸ’¾ Stateful Memory
- **Session Persistence**: Retains user context and personal details (e.g., names, facts) throughout the active session using robust in-memory checkpointing.

- **Thread Management**: Unique thread IDs ensure conversation isolation for multiple users.

### ğŸ›¡ï¸ Production Guardrails
- **Budget Circuit Breaker**: Automatically halts execution when daily token limits are exceeded.

- **Hallucination Filters**: Regex-based safety logic prevents the agent from performing unnecessary web searches for personal statements.

### ğŸ³ Fully Containerized
- Backend is fully Dockerized for consistent deployment across **Development**, **CI**, and **Production** environments.

### âœ… CI/CD Pipeline
- GitHub Actions automatically validate:
  - Agent logic correctness
  - Token budget accounting
  - Database path integrity

### ğŸ“„ Document Analysis (RAG)
- **Drag-and-Drop**: Upload PDF resumes, research papers, or contracts directly via the UI.

- **Local Embeddings**: Uses HuggingFaceEmbeddings and FAISS for fast, secure, CPU-optimized vector search.

- **Context Awareness**: The agent automatically detects if a file is uploaded and adjusts its system prompts accordingly.

## ğŸ› ï¸ Tech Stack
- **Brain**: Llama 3 (via NVIDIA NIM)

- **Orchestration**: LangChain + LangGraph

- **Backend**: FastAPI (Async Python)

- **Frontend**: Next.js 14, Tailwind CSS, Lucide React

- **Vector DB**: FAISS (Local)

## ğŸ’» Installation & Setup

### Prerequisites
* **Python 3.10+** and **Node.js 18+** installed.
* **Docker** & **Docker Compose** installed.
* API Keys for **NVIDIA NIM** (LLM) and **Tavily Search** (Web Browsing).

### Option A: Hybrid Run (Docker Backend + Local Frontend)

1.  **Start the Backend (Docker)**
    ```bash
    # Clone repository
    git clone https://github.com/PTX-Tien/project-vera.git
    cd project-vera

    # Create .env file
    echo "NVIDIA_API_KEY=nvapi-..." > .env
    echo "TAVILY_API_KEY=tvly-..." >> .env

    # Build and Run Container
    docker-compose up --build
    ```
    > Backend will be live at **[http://localhost:8000/](http://localhost:8000/)**

2.  **Start the Frontend (Local) Open a new terminal:**
    Create a `.env` file in the root directory and add your keys:
    ```bash
    cd vera-frontend
    npm install
    npm run dev
    ```
    > Access the app at **[http://localhost:3000/](http://localhost:3000/)**

### Option B: Full Local Development

1.  **Backend**
    ```bash
    cd project-vera
    pip install -r requirements.txt
    PYTHONPATH=src uvicorn api:app --reload --host 0.0.0.0 --port 8000
    ```
2.  **Frontend**
    ```bash
    cd vera-frontend
    npm run dev
    ```

---

## ğŸ“‚ Project Structure

```text
project-vera/
â”œâ”€â”€ .github/workflows/    # ğŸ¤– CI/CD Pipelines
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent.py          # ğŸ§  LangGraph Logic & Memory
â”‚   â”œâ”€â”€ api.py            # ğŸš€ FastAPI Endpoints & Lifespan Manager
â”‚   â”œâ”€â”€ rag_engine.py     # ğŸ“„ FAISS Vector Store & PDF Processing
â”‚   â””â”€â”€ budget.py         # ğŸ’³ Token Counting & Budget Logic
â”œâ”€â”€ vera-frontend/        # ğŸ’» Next.js Client Code
â”‚   â”œâ”€â”€ src/app/page.tsx  # âš›ï¸ Chat UI & State Logic
â”‚   â””â”€â”€ tailwind.config.ts
â”œâ”€â”€ docker-compose.yml    # ğŸ³ Infrastructure as Code
â”œâ”€â”€ Dockerfile            # ğŸ“¦ Container Definition
â””â”€â”€ requirements.txt      # ğŸ Python Dependencies